{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaoost\n",
    "### AdaBoost的一般流程\n",
    "（1）收集数据：可以使用任意方法。  \n",
    "（2）准备数据：依赖于所使用的弱分类器类型，本章使用的是单层决策树，这种分类器可以处理任何数据类型。当然也可以使用任意分类器作为弱分类器，作为弱分类器，简单分类器的效果更好。  \n",
    "（3）分析数据：可以使用任意方法。  \n",
    "（4）训练算法：AdaBoost的大部分时间都用在训练上，分类器将多次在同一数据集上训练弱分类器。  \n",
    "（5）测试算法：计算分类的错误率。  \n",
    "（6）使用算法：同SVM一样，AdaBoost预测两个类别中的一个。如果想把它应用到多个类别的场合，那么就要像多类SVM中的做法一样对AdaBoost进行修改。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost（Adaptive boosting）的运行过程：\n",
    "- 训练数据中的每个样本，并赋予其一个权重，这些权重构成了向量$D$。  \n",
    "- 一开始，这些权重都初始化成相等值。  \n",
    "- 首先，在训练数据上训练出一个弱分类器并计算该分类器的错误率，然后在同一数据集上再次训练弱分类器。  \n",
    "- 在分类器的第二次训练当中，将会重新调整每个样本的权重，其中第一次分对的样本的权重将会降低，而第一次分错的样本的权重将会提高。  \n",
    "- 为了从所有弱分类器中得到最终的分类结果，AdaBoost为每个分类器都分配了一个权重值alpha，这些alpha值是基于每个弱分类器的错误率进行计算的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中，错误率$ε$的定义为：\n",
    "$$ε=\\frac{未正确分类的样本数目}{所有样本数目}$$\n",
    "而alpha的计算公式如下： \n",
    "$$α= \\frac{1}{2}ln(\\frac{1-ε}{ε})$$\n",
    "计算出alpha值之后，可以对权重向量$D$进行更新，以使那些正确分类的样本的权重降低而错分样本的权重升高。$D$的计算方法如下： \n",
    "如果某个样本被正确分类，那么该样本的权重更改为： \n",
    "$$D_i^{(t+1)}=\\frac{D_i^{(t)}e^{-α}}{Sum(D)}$$\n",
    "而如果某个样本被错分，那么该样本的权重更改为;  \n",
    "$$D_i^{(t+1)}=\\frac{D_i^{(t)}e^{α}}{Sum(D)}$$\n",
    "在计算出$D$之后，AdaBoost又开始下一轮迭代。AdaBoost算法会不断重复训练和调整权重的过程，直到错误率为0或者弱分类器的数目达到用户的指定值为止。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\"\"\"\n",
    "函数说明:加载数据\n",
    "Parameters:\n",
    "    无\n",
    "Returns:\n",
    "    datMat - 数据列表\n",
    "    classLabels - 标签列表\n",
    "\"\"\"\n",
    "def loadSimpData():\n",
    "    datMat = np.matrix([[1.,2.1],\n",
    "                        [2.,1.1],\n",
    "                        [1.3,1.],\n",
    "                        [1.,1.],\n",
    "                        [2.,1.]])\n",
    "    classLabels = [1.0,1.0,-1.0,-1.0,1.0]\n",
    "    return datMat,classLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数说明:单层决策树分类函数\n",
    "Parameters:\n",
    "    dataMatrix - 数据矩阵\n",
    "    dimen - 第dimen列，即第dimen个特征\n",
    "    threshVal - 阈值\n",
    "    threshIneq - 标志，lt--less than；gt--great than\n",
    "Returns:\n",
    "    retArray - 分类结果\n",
    "\"\"\"\n",
    "def stumpClassify(dataMatrix,dimen,threshVal,threshIneq):\n",
    "    retArray = np.ones((dataMatrix.shape[0],1))             #将分类结果初始化为1\n",
    "    if threshIneq == 'lt':\n",
    "        retArray[dataMatrix[:,dimen] <= threshVal] = -1.0   #如果小于阈值，则分类结果为-1\n",
    "    else:\n",
    "        retArray[dataMatrix[:,dimen] > threshVal] = -1.0    #如果大于阈值，则分类结果为-1\n",
    "    return retArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数说明:找到数据集上最佳的单层决策树\n",
    "Parameters:\n",
    "    dataArr - 数据列表\n",
    "    classLabels - 标签列表\n",
    "    D - 样本权重\n",
    "Returns:\n",
    "    bestStump - 最佳单层决策树信息\n",
    "    minError - 最小错误率\n",
    "    bestClassEst - 最佳分类结果\n",
    "\"\"\"\n",
    "def buildStump(dataArr, classLabels,D):\n",
    "    dataMatrix = np.mat(dataArr); labelMat = np.mat(classLabels).T            #将训练数据和标签列表转换为numpy矩阵 np.mat()\n",
    "    m,n = np.shape(dataMatrix)                                                #返回训练数据的大小 np.shape()\n",
    "    numSteps = 10.0; bestStump = {}; bestClassEst = np.mat(np.zeros((m,1)))   #初始化\n",
    "    minError = np.inf                                                         #将最小错误率设置为无穷大\n",
    "    for i in range(n):                                                        #遍历所有特征\n",
    "        rangeMin = dataMatrix[:,i].min(); rangeMax = dataMatrix[:,i].max()    #找到该特征中最小和最大的值\n",
    "        stepSize = (rangeMax-rangeMin)/numSteps                               #计算步长\n",
    "        for j in range(-1,int(numSteps)+1):                                  \n",
    "            for inequal in ['lt','gt']:                                       #遍历大于和小于的情况\n",
    "                threshVal = (rangeMin+float(j)*stepSize)                      #计算阈值\n",
    "                predictedVals = stumpClassify(dataMatrix,i,threshVal,inequal) #计算分类结果\n",
    "                errArr = np.mat(np.ones((m,1)))                               #初始化误差矩阵\n",
    "                errArr[predictedVals == labelMat] = 0                         #若预测正确，赋值为0\n",
    "                weightedError = D.T*errArr                                    #计算加权误差率\n",
    "                #print(\"split: dim  %d, thresh  %.2f, thresh ineqal: %s, the weighted error is %.3f\" %(i, threshVal,inequal,weightedError))\n",
    "                if weightedError < minError:                                  #找到误差最小的分类方式（选取该特征作为树桩）\n",
    "                    minError = weightedError\n",
    "                    bestClassEst = predictedVals.copy()\n",
    "                    bestStump['dim'] = i                                      #将最佳单层决策树的信息存至字典\n",
    "                    bestStump['thresh'] = threshVal                           #最佳决策树桩由三个因素决定）\n",
    "                    bestStump['ineq'] = inequal                               #（所选特征：dim  所选阈值（0特征为定量资料时）：thresh   阳性事件的特征部分：ineq （即大于还是小于阈值时为正）\n",
    "    return bestStump,minError,bestClassEst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数说明:基于单层决策树的AdaBoost训练过程\n",
    "\n",
    "Parameters:\n",
    "    dataArr - 数据集\n",
    "    classLabels - 类别标签\n",
    "    numIt - 迭代次数\n",
    "Returns:\n",
    "    weakClassArr - 各层决策树信息\n",
    "\"\"\"\n",
    "def adaBoostTrainDS(dataArr, classLabels, numIt = 40):\n",
    "    weakClassArr = []\n",
    "    m = np.shape(dataArr)[0]\n",
    "    D = np.mat(np.ones((m,1))/m)                                                               #初始化样本权重\n",
    "    aggClassEst = np.mat(np.zeros((m,1)))                                                      #记录每个数据点的类别估计累计值\n",
    "    for i in range(numIt):\n",
    "        bestStump, error, classEst = buildStump(dataArr,classLabels,D)                         #构建单层决策树\n",
    "        #print(\"D: \", D.T)\n",
    "        alpha = float(0.5*np.log((1.0-error)/max(error,1e-16)))                                #根据公式计算弱学习算法权重\n",
    "        bestStump['alpha'] = alpha                                                             #存储弱学习算法权重\n",
    "        weakClassArr.append(bestStump)                                                         #存储单层决策树\n",
    "        #print(\"classEst: \", classEst.T)\n",
    "        expon = np.multiply(-1*alpha*np.mat(classLabels).T,classEst)                           #根据公式计算e的指数项\n",
    "        D = np.multiply(D,np.exp(expon))\n",
    "        D = D/D.sum()                                                                          #根据样本权重公式，为下一次迭代更新样本权重D\n",
    "        aggClassEst += alpha*classEst                                                          #将各数据点的类别估计值累加\n",
    "       # print(\"aggClassEst: \", aggClassEst.T)\n",
    "        aggErrors = np.multiply(np.sign(aggClassEst)!= np.mat(classLabels).T, np.ones((m,1)))  #计算误差\n",
    "        errorRate = aggErrors.sum()/m\n",
    "        print(\"total error:\", errorRate,\"\\n\")\n",
    "        if errorRate == 0.0: break\n",
    "    return weakClassArr,aggClassEst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数说明:AdaBoost分类函数\n",
    "\n",
    "Parameters:\n",
    "    datToClass    - 待分类数据集（测试集）\n",
    "    classifierArr - 训练好的多个弱分类器数组\n",
    "Returns:\n",
    "    分类结果\n",
    "\"\"\"\n",
    "def adaClassify(datToClass, classifierArr):\n",
    "    dataMatrix = np.mat(datToClass)                                                         #将待分类数据集转换为numpy矩阵\n",
    "    m = np.shape(dataMatrix)[0]                                                             #求得待分类数据的样本数\n",
    "    aggClassEst = np.mat(np.zeros((m,1)))                                                   #初始化分类结果\n",
    "    for i in range(len(classifierArr)):                                                     #遍历所有的分类器，进行分类\n",
    "        classEst = stumpClassify(dataMatrix,classifierArr[i]['dim'],classifierArr[i]['thresh'],classifierArr[i]['ineq'])\n",
    "        aggClassEst += classifierArr[i]['alpha']*classEst                                   #给样本的分类结果附上该分类器的权重并累加\n",
    "        #print(aggClassEst)\n",
    "    return np.sign(aggClassEst)                                                             #返回最终分类结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简单尝试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'dim': 0, 'thresh': 1.3, 'ineq': 'lt'}, matrix([[0.2]]), array([[-1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [ 1.]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datMat, classLabels = loadSimpData()   #载入训练数据集，真实label\n",
    "D = np.mat(np.ones((5, 1))/5)          #初始样本权重\n",
    "buildStump(datMat, classLabels, D)     #生成第一课决策树桩   结果为（分类特征去第一个，阈值为1.3，小于1。3的为label为正类）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total error: 0.2 \n",
      "\n",
      "total error: 0.2 \n",
      "\n",
      "total error: 0.0 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'dim': 0, 'thresh': 1.3, 'ineq': 'lt', 'alpha': 0.6931471805599453},\n",
       " {'dim': 1, 'thresh': 1.0, 'ineq': 'lt', 'alpha': 0.9729550745276565},\n",
       " {'dim': 0, 'thresh': 0.9, 'ineq': 'lt', 'alpha': 0.8958797346140273}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifierArray , aggClassEst = adaBoostTrainDS(datMat, classLabels, 10)     #迭代十次生成决策树桩为弱分类器的boosting分类模型         \n",
    "print(classifierArray)                                                       #各基本分类器（决策树桩）的信息，alpha为其权重\n",
    "print(aggClassEst)                                                           #每个数据点的类别最终估计累计值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.],\n",
       "        [-1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaClassify([[5, 5], [0, 0]], classifierArray)                               #预测分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 示例：在一个难数据集上应用AdaBoost\n",
    "（1）收集数据：提供的文本文件。  \n",
    "（2）准备数据：确保类别标签是+1和-1而非1和0。  \n",
    "（3）分析数据：手工检查数据。  \n",
    "（4）训练算法：在数据上，利用adaBoostTrainDS()函数训练出一系列的分类器。  \n",
    "（5）测试算法：我们拥有两个数据集。在不采用随机抽样的方法下，我们就会对AdaBoost和Logistic回归的结果进行完全对等的比较。  \n",
    "（6）使用算法：观察该例子上的错误率。不过，也可以构建一个Web网站，让驯马师输入马的症状然后预测马是否会死去。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数说明:自适应数据加载函数\n",
    "Parameters:\n",
    "    fileName - 文件名\n",
    "Returns:\n",
    "    dataMat- 数据集\n",
    "    labelMat- 标签列表\n",
    "\"\"\"\n",
    "def loadDataSet(fileName):\n",
    "    numFeat = len(open(fileName).readline().split('\\t'))         #获取特征数目\n",
    "    dataMat = []; labelMat = []\n",
    "    fr = open(fileName)                                          #打开文件\n",
    "    for line in fr.readlines():                                  #逐行读取\n",
    "        lineArr = []\n",
    "        curLine = line.strip().split('\\t')                       #去根据制表符分割，逐个放入列表\n",
    "        for i in range(numFeat-1):\n",
    "            lineArr.append(float(curLine[i]))                    #前num-1列放入训练特征数据\n",
    "        dataMat.append(lineArr)                                  #添加数据\n",
    "        labelMat.append(float(curLine[-1]))                      #添加标签，最后一列\n",
    "    return dataMat,labelMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total error: 0.2842809364548495 \n",
      "\n",
      "total error: 0.2842809364548495 \n",
      "\n",
      "total error: 0.24749163879598662 \n",
      "\n",
      "total error: 0.24749163879598662 \n",
      "\n",
      "total error: 0.25418060200668896 \n",
      "\n",
      "total error: 0.2408026755852843 \n",
      "\n",
      "total error: 0.2408026755852843 \n",
      "\n",
      "total error: 0.22073578595317725 \n",
      "\n",
      "total error: 0.24749163879598662 \n",
      "\n",
      "total error: 0.23076923076923078 \n",
      "\n",
      "total error: 0.2408026755852843 \n",
      "\n",
      "total error: 0.2140468227424749 \n",
      "\n",
      "total error: 0.22742474916387959 \n",
      "\n",
      "total error: 0.21739130434782608 \n",
      "\n",
      "total error: 0.22073578595317725 \n",
      "\n",
      "total error: 0.21739130434782608 \n",
      "\n",
      "total error: 0.22408026755852842 \n",
      "\n",
      "total error: 0.22408026755852842 \n",
      "\n",
      "total error: 0.23076923076923078 \n",
      "\n",
      "total error: 0.22408026755852842 \n",
      "\n",
      "total error: 0.2140468227424749 \n",
      "\n",
      "total error: 0.20735785953177258 \n",
      "\n",
      "total error: 0.22408026755852842 \n",
      "\n",
      "total error: 0.22408026755852842 \n",
      "\n",
      "total error: 0.2140468227424749 \n",
      "\n",
      "total error: 0.22073578595317725 \n",
      "\n",
      "total error: 0.2040133779264214 \n",
      "\n",
      "total error: 0.20735785953177258 \n",
      "\n",
      "total error: 0.21070234113712374 \n",
      "\n",
      "total error: 0.21739130434782608 \n",
      "\n",
      "total error: 0.21070234113712374 \n",
      "\n",
      "total error: 0.21739130434782608 \n",
      "\n",
      "total error: 0.20735785953177258 \n",
      "\n",
      "total error: 0.21070234113712374 \n",
      "\n",
      "total error: 0.20735785953177258 \n",
      "\n",
      "total error: 0.20735785953177258 \n",
      "\n",
      "total error: 0.19732441471571907 \n",
      "\n",
      "total error: 0.19063545150501673 \n",
      "\n",
      "total error: 0.20066889632107024 \n",
      "\n",
      "total error: 0.19732441471571907 \n",
      "\n",
      "total error: 0.20066889632107024 \n",
      "\n",
      "total error: 0.1939799331103679 \n",
      "\n",
      "total error: 0.1939799331103679 \n",
      "\n",
      "total error: 0.19063545150501673 \n",
      "\n",
      "total error: 0.18729096989966554 \n",
      "\n",
      "total error: 0.19063545150501673 \n",
      "\n",
      "total error: 0.19063545150501673 \n",
      "\n",
      "total error: 0.18729096989966554 \n",
      "\n",
      "total error: 0.1939799331103679 \n",
      "\n",
      "total error: 0.18729096989966554 \n",
      "\n",
      "total error: 0.1939799331103679 \n",
      "\n",
      "total error: 0.18394648829431437 \n",
      "\n",
      "total error: 0.1939799331103679 \n",
      "\n",
      "total error: 0.18394648829431437 \n",
      "\n",
      "total error: 0.1939799331103679 \n",
      "\n",
      "total error: 0.19063545150501673 \n",
      "\n",
      "total error: 0.19732441471571907 \n",
      "\n",
      "total error: 0.1939799331103679 \n",
      "\n",
      "total error: 0.18729096989966554 \n",
      "\n",
      "total error: 0.18729096989966554 \n",
      "\n",
      "total error: 0.1939799331103679 \n",
      "\n",
      "total error: 0.1939799331103679 \n",
      "\n",
      "total error: 0.1939799331103679 \n",
      "\n",
      "total error: 0.1939799331103679 \n",
      "\n",
      "total error: 0.1939799331103679 \n",
      "\n",
      "total error: 0.19063545150501673 \n",
      "\n",
      "total error: 0.18729096989966554 \n",
      "\n",
      "total error: 0.19063545150501673 \n",
      "\n",
      "total error: 0.19063545150501673 \n",
      "\n",
      "total error: 0.1939799331103679 \n",
      "\n",
      "total error: 0.19063545150501673 \n",
      "\n",
      "total error: 0.19063545150501673 \n",
      "\n",
      "total error: 0.18394648829431437 \n",
      "\n",
      "total error: 0.18729096989966554 \n",
      "\n",
      "total error: 0.18729096989966554 \n",
      "\n",
      "total error: 0.19063545150501673 \n",
      "\n",
      "total error: 0.18729096989966554 \n",
      "\n",
      "total error: 0.19063545150501673 \n",
      "\n",
      "total error: 0.1806020066889632 \n",
      "\n",
      "total error: 0.1939799331103679 \n",
      "\n",
      "total error: 0.18394648829431437 \n",
      "\n",
      "total error: 0.18729096989966554 \n",
      "\n",
      "total error: 0.18394648829431437 \n",
      "\n",
      "total error: 0.18729096989966554 \n",
      "\n",
      "total error: 0.18394648829431437 \n",
      "\n",
      "total error: 0.19063545150501673 \n",
      "\n",
      "total error: 0.18729096989966554 \n",
      "\n",
      "total error: 0.1939799331103679 \n",
      "\n",
      "total error: 0.18729096989966554 \n",
      "\n",
      "total error: 0.19063545150501673 \n",
      "\n",
      "total error: 0.18394648829431437 \n",
      "\n",
      "total error: 0.18394648829431437 \n",
      "\n",
      "total error: 0.18394648829431437 \n",
      "\n",
      "total error: 0.19063545150501673 \n",
      "\n",
      "total error: 0.18729096989966554 \n",
      "\n",
      "total error: 0.19732441471571907 \n",
      "\n",
      "total error: 0.19063545150501673 \n",
      "\n",
      "total error: 0.1939799331103679 \n",
      "\n",
      "total error: 0.19063545150501673 \n",
      "\n",
      "total error: 0.19063545150501673 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[-4.76288936e-01],\n",
       "        [ 5.00472043e-01],\n",
       "        [ 1.68185951e+00],\n",
       "        [-3.06280512e-01],\n",
       "        [-1.17721870e-01],\n",
       "        [ 1.45087199e+00],\n",
       "        [ 1.29047637e+00],\n",
       "        [ 5.83370911e-01],\n",
       "        [-5.81538319e-01],\n",
       "        [ 1.11192984e+00],\n",
       "        [-2.46399930e-01],\n",
       "        [ 9.07913854e-01],\n",
       "        [ 1.70923415e+00],\n",
       "        [ 3.39705491e-01],\n",
       "        [ 8.86551131e-01],\n",
       "        [-3.33205255e-01],\n",
       "        [-1.53460457e+00],\n",
       "        [ 2.27718685e-01],\n",
       "        [ 1.69052655e-01],\n",
       "        [ 1.45041603e-01],\n",
       "        [ 2.57488772e-01],\n",
       "        [ 2.21152265e+00],\n",
       "        [ 1.87662364e+00],\n",
       "        [ 1.62715734e+00],\n",
       "        [ 7.78156549e-01],\n",
       "        [ 1.38418435e-01],\n",
       "        [ 4.93782418e-01],\n",
       "        [ 6.92121875e-01],\n",
       "        [ 9.17028421e-02],\n",
       "        [ 2.68608993e+00],\n",
       "        [-8.43636370e-01],\n",
       "        [ 2.08895840e-01],\n",
       "        [ 1.07068262e+00],\n",
       "        [ 5.79339303e-01],\n",
       "        [-7.20874734e-03],\n",
       "        [-2.07179305e+00],\n",
       "        [-6.01594559e-01],\n",
       "        [ 4.07551086e-01],\n",
       "        [ 2.05801312e+00],\n",
       "        [ 1.53711197e-01],\n",
       "        [-2.36735168e+00],\n",
       "        [ 3.44630078e-01],\n",
       "        [ 9.51812135e-01],\n",
       "        [-1.02632904e+00],\n",
       "        [-1.81060209e+00],\n",
       "        [-1.07220340e+00],\n",
       "        [-1.00876567e+00],\n",
       "        [ 2.08840656e+00],\n",
       "        [-8.55564889e-01],\n",
       "        [-2.11966855e+00],\n",
       "        [ 1.57613249e+00],\n",
       "        [ 5.00987305e-01],\n",
       "        [ 1.78659168e+00],\n",
       "        [ 5.72560754e-01],\n",
       "        [-4.90164320e-01],\n",
       "        [-3.11226707e-01],\n",
       "        [ 3.58751571e-01],\n",
       "        [-3.38611643e-01],\n",
       "        [-6.78495556e-01],\n",
       "        [-1.33737177e+00],\n",
       "        [ 1.35314522e+00],\n",
       "        [ 1.76246793e+00],\n",
       "        [-5.25383184e-01],\n",
       "        [ 1.44174526e-01],\n",
       "        [-4.69512081e-01],\n",
       "        [ 7.07793745e-01],\n",
       "        [ 3.24788112e-01],\n",
       "        [ 2.40157794e+00],\n",
       "        [ 1.15120935e-01],\n",
       "        [ 1.87160175e+00],\n",
       "        [-6.04427112e-01],\n",
       "        [ 1.84721269e+00],\n",
       "        [-1.43079026e-01],\n",
       "        [-1.08696166e+00],\n",
       "        [ 2.48754106e-01],\n",
       "        [-4.59528428e-01],\n",
       "        [ 1.78957184e+00],\n",
       "        [ 2.08840748e+00],\n",
       "        [-2.06700751e-01],\n",
       "        [ 3.61193765e-01],\n",
       "        [-5.10297649e-01],\n",
       "        [ 8.75945117e-01],\n",
       "        [ 7.32162396e-01],\n",
       "        [-1.74585946e+00],\n",
       "        [-1.06565931e-03],\n",
       "        [ 2.18618286e+00],\n",
       "        [-1.26983965e+00],\n",
       "        [ 7.50385368e-01],\n",
       "        [ 1.33726133e+00],\n",
       "        [ 2.65866329e+00],\n",
       "        [ 1.05387421e+00],\n",
       "        [-4.90164320e-01],\n",
       "        [ 1.56863391e+00],\n",
       "        [-2.29309726e-01],\n",
       "        [ 1.63400913e+00],\n",
       "        [ 1.53634676e+00],\n",
       "        [ 1.06850366e+00],\n",
       "        [-1.26819893e+00],\n",
       "        [ 1.97552387e+00],\n",
       "        [-5.86285782e-01],\n",
       "        [ 1.98904696e+00],\n",
       "        [-1.89827827e+00],\n",
       "        [ 1.01122742e+00],\n",
       "        [ 1.61082921e+00],\n",
       "        [ 2.35035702e-03],\n",
       "        [ 8.94003329e-01],\n",
       "        [ 9.93447398e-01],\n",
       "        [ 2.25564810e+00],\n",
       "        [-7.26022476e-01],\n",
       "        [-7.64754279e-01],\n",
       "        [-9.59915862e-01],\n",
       "        [ 1.37285151e+00],\n",
       "        [ 1.34478308e+00],\n",
       "        [-8.79997440e-01],\n",
       "        [ 4.60072162e-01],\n",
       "        [ 2.11579108e+00],\n",
       "        [ 2.77990986e+00],\n",
       "        [ 1.11793688e-01],\n",
       "        [ 3.65477197e-01],\n",
       "        [ 1.13547468e+00],\n",
       "        [ 1.54589796e+00],\n",
       "        [-1.22558224e+00],\n",
       "        [ 2.19081685e+00],\n",
       "        [-5.91620398e-01],\n",
       "        [ 5.05773041e-01],\n",
       "        [ 1.89059796e+00],\n",
       "        [ 2.41490113e-01],\n",
       "        [ 7.85865867e-01],\n",
       "        [-7.33351255e-01],\n",
       "        [ 1.46340153e+00],\n",
       "        [ 4.38502859e-01],\n",
       "        [ 9.85745298e-02],\n",
       "        [ 1.55346685e+00],\n",
       "        [-6.83007127e-01],\n",
       "        [-7.12665860e-01],\n",
       "        [-2.06700751e-01],\n",
       "        [ 1.46009229e+00],\n",
       "        [ 2.13576315e+00],\n",
       "        [ 1.15250791e+00],\n",
       "        [ 9.38985803e-01],\n",
       "        [-6.25863809e-01],\n",
       "        [-1.18397068e+00],\n",
       "        [ 1.84721269e+00],\n",
       "        [-1.29980299e-01],\n",
       "        [ 8.77292574e-01],\n",
       "        [ 1.90311989e+00],\n",
       "        [ 8.50519734e-01],\n",
       "        [-1.60187894e-01],\n",
       "        [ 1.66785703e+00],\n",
       "        [ 2.16171145e+00],\n",
       "        [-1.64135490e+00],\n",
       "        [-2.93456921e-01],\n",
       "        [ 1.67638594e+00],\n",
       "        [ 3.05102327e+00],\n",
       "        [ 7.80266944e-01],\n",
       "        [ 1.50437573e+00],\n",
       "        [ 6.39392884e-01],\n",
       "        [ 1.42166441e+00],\n",
       "        [ 1.82449723e+00],\n",
       "        [-9.57380981e-01],\n",
       "        [ 3.34886096e-01],\n",
       "        [ 2.08852401e+00],\n",
       "        [-1.05055637e-01],\n",
       "        [ 5.50688726e-01],\n",
       "        [ 7.17619558e-02],\n",
       "        [ 2.61999676e+00],\n",
       "        [ 1.56604853e+00],\n",
       "        [ 3.20935716e-01],\n",
       "        [-1.62425232e+00],\n",
       "        [ 1.52773961e+00],\n",
       "        [-1.53870634e+00],\n",
       "        [-6.62047268e-01],\n",
       "        [-1.75243227e+00],\n",
       "        [-9.31180615e-01],\n",
       "        [ 9.17028421e-02],\n",
       "        [ 2.78013407e+00],\n",
       "        [-2.29123847e+00],\n",
       "        [-2.01947571e-01],\n",
       "        [-8.97463355e-01],\n",
       "        [-1.79297042e+00],\n",
       "        [ 8.30800596e-01],\n",
       "        [-1.74585946e+00],\n",
       "        [ 2.43342588e+00],\n",
       "        [ 2.50962625e+00],\n",
       "        [-3.53245423e-01],\n",
       "        [ 1.04990644e+00],\n",
       "        [ 8.53277287e-02],\n",
       "        [ 1.61185208e+00],\n",
       "        [ 5.65728217e-01],\n",
       "        [ 1.55509792e+00],\n",
       "        [ 5.65595244e-01],\n",
       "        [ 2.24345851e+00],\n",
       "        [-1.55462287e+00],\n",
       "        [ 7.63380999e-01],\n",
       "        [ 2.67187065e+00],\n",
       "        [-3.01379193e-01],\n",
       "        [ 1.08360541e-02],\n",
       "        [ 1.91155816e+00],\n",
       "        [ 1.16375535e+00],\n",
       "        [ 2.06606656e+00],\n",
       "        [-2.65129005e-01],\n",
       "        [ 4.63078194e-01],\n",
       "        [ 2.39843995e+00],\n",
       "        [-8.23647972e-02],\n",
       "        [-8.97463355e-01],\n",
       "        [ 9.90936621e-01],\n",
       "        [ 5.15944828e-01],\n",
       "        [-7.04682148e-01],\n",
       "        [ 2.66171898e+00],\n",
       "        [-2.48724816e-01],\n",
       "        [-8.86593642e-01],\n",
       "        [ 9.63863810e-01],\n",
       "        [ 1.10806691e+00],\n",
       "        [ 2.07821435e+00],\n",
       "        [ 2.51215726e+00],\n",
       "        [ 3.29377500e-01],\n",
       "        [-4.21620852e-01],\n",
       "        [ 9.43492169e-01],\n",
       "        [ 9.42798910e-02],\n",
       "        [-1.14172831e+00],\n",
       "        [ 7.16587020e-01],\n",
       "        [-2.39583992e-01],\n",
       "        [ 1.29519644e+00],\n",
       "        [ 2.31192079e+00],\n",
       "        [ 2.21829692e+00],\n",
       "        [-2.03636442e+00],\n",
       "        [ 4.29460207e-01],\n",
       "        [-1.76020818e+00],\n",
       "        [ 1.53248604e+00],\n",
       "        [-4.35531786e-01],\n",
       "        [-1.66362362e+00],\n",
       "        [ 8.62744845e-01],\n",
       "        [ 4.93782418e-01],\n",
       "        [ 1.63400913e+00],\n",
       "        [-1.08696166e+00],\n",
       "        [ 1.71781464e+00],\n",
       "        [ 1.50936032e+00],\n",
       "        [ 6.63167816e-02],\n",
       "        [-9.82586097e-02],\n",
       "        [-1.12127692e+00],\n",
       "        [ 1.69770774e+00],\n",
       "        [-2.53825646e-01],\n",
       "        [-3.95251484e-01],\n",
       "        [ 1.17834098e+00],\n",
       "        [-1.14891387e+00],\n",
       "        [-7.28025113e-01],\n",
       "        [-1.13641531e+00],\n",
       "        [ 1.28927538e-01],\n",
       "        [ 2.27932938e+00],\n",
       "        [-7.65958751e-01],\n",
       "        [ 4.85583820e-01],\n",
       "        [ 2.20119418e-01],\n",
       "        [-5.75402390e-01],\n",
       "        [-3.74604873e-01],\n",
       "        [-4.06022930e-02],\n",
       "        [ 1.28359624e+00],\n",
       "        [-1.39406702e+00],\n",
       "        [ 2.48893320e+00],\n",
       "        [ 3.45569983e-01],\n",
       "        [ 1.11322606e+00],\n",
       "        [ 1.96907644e+00],\n",
       "        [-5.93503481e-01],\n",
       "        [-6.36473317e-01],\n",
       "        [ 9.97764170e-02],\n",
       "        [ 1.19206796e+00],\n",
       "        [ 6.17852088e-01],\n",
       "        [ 3.84497391e-01],\n",
       "        [ 1.38656127e+00],\n",
       "        [ 4.73282141e-01],\n",
       "        [ 5.49591415e-01],\n",
       "        [-8.52793166e-02],\n",
       "        [-7.20874734e-03],\n",
       "        [-1.89900625e+00],\n",
       "        [-4.86393162e-01],\n",
       "        [ 2.96476792e-01],\n",
       "        [ 8.03746667e-01],\n",
       "        [ 1.62307797e+00],\n",
       "        [ 2.33246135e+00],\n",
       "        [ 3.78280226e-01],\n",
       "        [ 2.14379954e+00],\n",
       "        [-9.90996637e-01],\n",
       "        [-9.59915862e-01],\n",
       "        [ 2.32954045e-01],\n",
       "        [ 2.63519929e+00],\n",
       "        [ 1.31859959e+00],\n",
       "        [-1.40905754e+00],\n",
       "        [ 3.95671093e-03],\n",
       "        [ 9.17028421e-02],\n",
       "        [ 2.17455614e+00],\n",
       "        [ 2.14133018e+00],\n",
       "        [-8.55564889e-01],\n",
       "        [-1.30692471e+00],\n",
       "        [-9.20917208e-01],\n",
       "        [ 3.18043367e+00],\n",
       "        [-2.16717812e-01],\n",
       "        [-1.31768944e+00],\n",
       "        [-1.15061675e+00],\n",
       "        [-1.43816255e-01],\n",
       "        [ 8.45761360e-01]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataMat,labelMat = loadDataSet('C:/Users/Administrator/horseColicTraining2.txt')  #载入训练集\n",
    "classifierArray,aggClassEst = adaBoostTrainDS(dataMat,labelMat,100)                #训练模型\n",
    "aggClassEst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19063545150501673"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testeMat,testLabelMat = loadDataSet('C:/Users/Administrator/horseColicTraining2.txt')   #载入测试集\n",
    "prediction10 = adaClassify(testeMat,classifierArray)                                    #利用训练好的adaboost模型预测           \n",
    "\n",
    "m,n = np.shape(testeMat)                                                                #测试集行列数目                                                          \n",
    "errArr = np.mat(np.ones((m,1)))                                                         #初始化错判向量                             \n",
    "errArr = np.multiply((prediction10!=np.mat(testLabelMat).T),errArr)                     #错判数目   （利用向量化计算）\n",
    "errRate = errArr.sum()/m                                                                #求得预测错误率\n",
    "errRate                                                                                 #错判率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 其他分类性能度量指标：正确率、召回率及ROC曲线\n",
    "- 混淆矩阵中有真正例（TP）、伪正例（FP）、伪反例（FN）、真反例（TN）\n",
    "- 正确率（presion）为TP/(TP+FP)，给出的是预测为正例的样本中的真正正例的比例。\n",
    "- 召回率（recall）为TP/(TP+FN)，给出的是预测为正例的真实正例占所有真实正例的比例。\n",
    "- ROC曲线（ROC curve），ROC代表接收者操作特征（receiver operating characteristic）。\n",
    "- ROC曲线下的面积AUC(Area Under the Curve)给出的是分类器的平均性能值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数说明:ROC曲线的绘制及AUC计算函数\n",
    "\n",
    "Parameters:\n",
    "    predStrengths - 每个数据点的类别估计累计值\n",
    "    classLabels -   标签列表\n",
    "Returns:\n",
    "    无\n",
    "\"\"\"\n",
    "def plotROC(predStrengths, classLabels):\n",
    "    import matplotlib.pyplot as plt\n",
    "    cur = (1.0,1.0)     #绘制光标的位置\n",
    "    ySum = 0.0          #用于计算AUC\n",
    "    numPosClas = sum(np.array(classLabels)==1.0)    #统计正类的数量\n",
    "    yStep = 1/float(numPosClas)                     #确定y轴的步长: Y轴步长为 1/真实正类个数    Y轴为真阳性率：TP/(TP+FN)\n",
    "    xStep = 1/float(len(classLabels)-numPosClas)    #确定x轴的步长：X轴步长为 1/真实反类个数    X轴为假阳性率：FP/(FP+TN)\n",
    "    sortedIndicies = predStrengths.argsort()        #得到排序索引\n",
    "    fig = plt.figure()                              #构建画笔\n",
    "    fig.clf()\n",
    "    ax = plt.subplot(111)\n",
    "    for index in sortedIndicies.tolist()[0]:        #在所有排序值上进行循环\n",
    "        if classLabels[index] == 1.0:\n",
    "            delX = 0; delY = yStep                  #每得到一个正类，就沿着y轴方向下降一个步长，不断降低真阳率\n",
    "        else:\n",
    "            delX =xStep; delY=0                     #其他类就沿着x轴方向倒退一个步长\n",
    "            ySum += cur[1]                          #计算面积是小矩形的宽度是xStep，高度累加\n",
    "        ax.plot([cur[0],cur[0]-delX],[cur[1],cur[1]-delY],c='b')\n",
    "        cur = (cur[0]-delX,cur[1]-delY)\n",
    "    ax.plot([0,1],[0,1],'b--')\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve for AdaBoost Horse Colic Detection System')\n",
    "    ax.axis([0,1,0,1])\n",
    "    plt.show()\n",
    "    print('the Area Under the Curve is: ', ySum*xStep)      #计算AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the Area Under the Curve is:  0.9070015786052564\n"
     ]
    }
   ],
   "source": [
    "plotROC(aggClassEst.T, labelMat)                   #输入每个数据点的类别估计累计值aggClassEst ，以及真实label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
